{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES\n",
    "\n",
    "todos_portais = ['Band','BBC','Folha de SP','Gazeta do Povo','Globo',\n",
    "                 'iG','R7','UOL','Veja','Carta Capital','Revista Forúm',\n",
    "                 'Brasil de Fato','Pleno News','Terça Livre','Renova Mídia',\n",
    "                'Conexão Política','Jornal da Cidade','El Pais', 'Deutsche Welle','Estadão','Isto É']\n",
    "\n",
    "# Band  -- OK\n",
    "band = 'https://www.band.uol.com.br'\n",
    "\n",
    "# BBC  -- OK\n",
    "bbc = 'https://www.bbc.com/portuguese'\n",
    "\n",
    "# Folha de SP  -- OK\n",
    "folha = 'https://www.folha.uol.com.br/'\n",
    "\n",
    "# Gazeta do Povo  -- OK    \n",
    "gazeta = 'https://www.gazetadopovo.com.br/'\n",
    "\n",
    "# Globo  -- OK\n",
    "globo = 'https://www.globo.com/'\n",
    "\n",
    "# iG  -- OK\n",
    "ig = 'https://www.ig.com.br/'\n",
    "\n",
    "# R7 -- OK\n",
    "r7 = 'https://www.r7.com/'\n",
    "\n",
    "# UOL  -- OK\n",
    "uol = 'https://www.uol.com.br/'\n",
    "\n",
    "# Veja  -- OK\n",
    "veja = 'https://veja.abril.com.br/'\n",
    "\n",
    "# Carta Capital  -- OK\n",
    "carta_capital = 'https://www.cartacapital.com.br/'\n",
    "\n",
    "# Revista Forúm  -- OK\n",
    "forum = 'https://revistaforum.com.br/'\n",
    "\n",
    "# Brasil de Fato  -- OK\n",
    "brasil_fato = 'https://www.brasildefato.com.br/'\n",
    "\n",
    "# Pleno News  -- OK\n",
    "pleno = 'https://pleno.news/'\n",
    "\n",
    "# Terça Livre  -- OK\n",
    "terca_livre = 'https://tercalivre.com.br/'\n",
    "\n",
    "# Renova Mídia  -- OK\n",
    "renova = 'https://renovamidia.com.br/?utm_source=rfrsh'\n",
    "\n",
    "# Conexão Política  -- OK\n",
    "conexao = 'https://www.conexaopolitica.com.br/'\n",
    "\n",
    "# Jornal da Cidade  -- OK\n",
    "jornal_cidade = 'https://www.jornaldacidadeonline.com.br/'\n",
    "\n",
    "# El Pais  -- OK\n",
    "elpais = 'https://brasil.elpais.com/'\n",
    "\n",
    "# Deutsche Welle  -- OK\n",
    "dw = 'https://www.dw.com/pt-br/not%C3%ADcias/s-7111'\n",
    "\n",
    "# Estadão  -- OK\n",
    "estadao = 'https://www.estadao.com.br/'\n",
    "\n",
    "# Isto É  -- OK\n",
    "istoe = 'https://istoe.com.br/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def coletando_infos_band():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = ['Em Alta','Tóquio no Bandsports','Notícias','Entretenimento','Esporte','Receitas','Web Stories','Nosso Time','Mais Vistos','1','2','3','4','5','6','Programas']\n",
    "    \n",
    "    r = requests.get(band)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h2'):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Band', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_bbc():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(bbc)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h3'):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'BBC', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_folha():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = ['Mais lidas', 'editoriais o que a folha pensa', 'tendências / debates', 'painel do leitor', 'TV Folha', 'Fotografia']\n",
    "    \n",
    "    r = requests.get(folha)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    for a in soup.find_all('h2'):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    for b in soup.find_all('span', class_='c-list-links__title'):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for c in soup.find_all('p', class_='c-rotate-headlines__description'):\n",
    "        manchete = c.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete.split(' -')[0])\n",
    "        \n",
    "              \n",
    "    infos_completas=[[hora_dia,'Folha de SP', x] for x in infos]\n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_gazeta():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = ['Quero receber','Gazeta do Povo','Notícias','Opinião','Mais','Informações','Notificações','NOTÍCIAS','LINHA DO TEMPO','PODCAST','KIT ANTICORRUPÇÃO','SaibaAgora','Ideias','Família e Bem-estar']\n",
    "    \n",
    "    r = requests.get(gazeta)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h2'):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for b in soup.find_all('a',class_='trigger-gtm'):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Gazeta do Povo', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_globo():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = ['MEGAPIX AO VIVO','OFF','SPORTV AO VIVO']\n",
    "    \n",
    "    r = requests.get(globo)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h3'):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for b in soup.find_all('h4'):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Globo', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_ig():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = [' ']\n",
    "    \n",
    "    r = requests.get(ig)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('a', {'data-tb-region-item': 'taboola-region'}):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for b in soup.find_all('a', {'class': 'title'}):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for c in soup.find_all('h2', {'class': 'sliderV5_container_desc_titulo'}):\n",
    "        manchete = c.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for d in soup.find_all('li', {'class': 'secondary-calling'}):\n",
    "        manchete = d.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for e in soup.find_all('li', {'class': 'chamada-secundaria'}):\n",
    "        manchete = e.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for f in soup.find_all('h2', {'class': 'componenteDestaqueSecao-contentText-titulo'}):\n",
    "        manchete = f.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for g in soup.find_all('h2', {'class': 'componenteDestaqueSecao-horizontal-flex-contentText-titulo'}):\n",
    "        manchete = g.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for h in soup.find_all('h2', {'class': 'componenteDestaqueSecao-horizontal-contentText-titulo'}):\n",
    "        manchete = h.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for i in soup.find_all('li', {'class': 'segunda-chamada'}):\n",
    "        manchete = i.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    infos_completas=[[hora_dia,'iG', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_r7():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(r7)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h3', {'class':['r7-flex-title-h1','r7-flex-title-h2','r7-flex-title-h3','r7-flex-title-h4','r7-flex-title-h5','r7-flex-title-h6']}):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    for b in soup.find_all('h4', {'class':['r7-flex-title-h1','r7-flex-title-h2','r7-flex-title-h3','r7-flex-title-h4','r7-flex-title-h5','r7-flex-title-h6']}):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    infos_completas=[[hora_dia,'R7', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_uol():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(uol)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h1', {'class':'titulo color2'}):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for b in soup.find_all('span', {'class':['linha font1 cor2-hover cor2-p4-hover cor-transition','color2','title cor-transition cor2-hover cor2-p4-hover','chamada corb cor2-hover cor2-p4-hover cor-transition','chamada cor2-hover cor2-p4-hover cor-transition','chamada cor2-hover cor-transition']}):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for c in soup.find_all('h2', {'class':'titulo color2'}):\n",
    "        manchete = c.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for d in soup.find_all('p', {'class':['subtitle titulo','texto color2']}):\n",
    "        manchete = d.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "        \n",
    "    infos_completas=[[hora_dia,'UOL', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_veja():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(veja)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h2', {'class':['title']}):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for b in soup.find_all('a', {'class':['link related-article']}):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for c in soup.find_all('h3', {'class':['title']}):\n",
    "        manchete = c.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for d in soup.find_all('h4', {'class':['title']}):\n",
    "        manchete = d.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Veja', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_carta_capital():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = ['Jornalismo crítico e transparente. Notícias sobre política, economia e sociedade com olhar progressista - Carta Capital','O que pensam os políticos do campo progressista']\n",
    "    \n",
    "    r = requests.get(carta_capital)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h1'):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for b in soup.find_all('li',{'class':['li_meta_related_matters']}):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for c in soup.find_all('div', class_='wpb_wrapper'):\n",
    "        for d in c.find_all('ul'):\n",
    "            for e in d.find_all('li'):\n",
    "                manchete = e.text.strip()\n",
    "                if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "                    infos.append(manchete)\n",
    "    \n",
    "    for f in soup.find_all('h3'):\n",
    "        manchete = f.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for g in soup.find_all('h4'):\n",
    "        manchete = g.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for h in soup.find_all('h5'):\n",
    "        manchete = h.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for i in soup.find_all('div', class_='txt'):\n",
    "        for j in i.find_all('a'):\n",
    "            manchete = j.text.strip()\n",
    "            if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "                infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Carta Capital', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_forum():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(forum)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('a',{'class':['rf_item','rf-post-title']}):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "    \n",
    "    for b in soup.find_all('div',{'class':['rf_blog_destaque_item_content']}):\n",
    "        for c in b.find_all('h3'):\n",
    "            manchete = c.text.strip()\n",
    "            if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "                infos.append(manchete)\n",
    "                \n",
    "\n",
    "    infos_completas=[[hora_dia,'Revista Forúm', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_brasil_fato():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(brasil_fato)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h3',{'class':['big-title','title']}):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for b in soup.find_all('h2',{'class':['title']}):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Brasil de Fato', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_pleno():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(pleno)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('div',{'class':['text','holder-box']}):\n",
    "        for b in a.find_all('h2'):\n",
    "            manchete = b.text.strip()\n",
    "            if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "                infos.append(manchete)\n",
    "    \n",
    "    for c in soup.find_all('div',{'class':['post-block small','post-block small height-1','holder-box']}):\n",
    "        for d in c.find_all('h3'):\n",
    "            manchete = d.text.strip()\n",
    "            if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "                infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Pleno News', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_terca_livre():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(terca_livre)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h2', class_='entry-title h6'):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Terça Livre', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_renova():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(renova)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h3', {'class':['elementor-post__title']}):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Renova Mídia', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_conexao():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(conexao)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('div', {'class':['mvp-feat1-sub-text','mvp-widget-feat1-top-text left relative','mvp-widget-feat1-bot-text left relative','mvp-feat1-feat-text left relative','mvp-widget-feat2-right-text left relative','mvp-feat1-list-text','mvp-blog-story-text left relative']}):\n",
    "        for b in a.find_all('h2'):\n",
    "            manchete = b.text.strip()\n",
    "            if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "                infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Conexão Política', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_jornal_cidade():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(jornal_cidade)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('a',{'class':['widget__title','widget__title font-bold block']}):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Jornal da Cidade', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_elpais():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(elpais)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h2'):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for b in soup.find_all('a',{'class':['c_r_s_h related_story_headline']}):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'El Pais', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_dw():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = ['Temas recorrentes','Boletim de notícias em áudio']\n",
    "    \n",
    "    r = requests.get(dw)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h2'):\n",
    "        if a.span is None:\n",
    "            manchete = a.text.strip()\n",
    "        else:\n",
    "            a.span.decompose()\n",
    "            manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Deutsche Welle', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_estadao():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(estadao)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('h3',{'class':['title']}):\n",
    "        manchete = a.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "            \n",
    "    for b in soup.find_all('h4',{'class':['bullets-title']}):\n",
    "        manchete = b.text.strip()\n",
    "        if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "            infos.append(manchete)\n",
    "        \n",
    "    infos_completas=[[hora_dia,'Estadão', x] for x in infos]  \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def coletando_infos_istoe():\n",
    "    infos = []\n",
    "    hora_dia = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    frases_comuns = []\n",
    "    \n",
    "    r = requests.get(istoe)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('div',{'class':['titulo-destaque-chamadas','bloco-noticias','wrapper-title']}):\n",
    "        for b in a.find_all('h1'):\n",
    "            manchete = b.text.strip()\n",
    "            if manchete!='' and manchete not in infos and manchete not in frases_comuns:\n",
    "                infos.append(manchete)\n",
    "\n",
    "    infos_completas=[[hora_dia,'Isto É', x] for x in infos]    \n",
    "    return infos_completas\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  FUNÇÕES AUXILIARES   ###\n",
    "\n",
    "def abrir_pickle(nome_portal):\n",
    "    with open('Manchetes/{}.pickle'.format(nome_portal), 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "        f.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def salvar_pickle(df,nome_portal):\n",
    "    with open('Manchetes/{}.pickle'.format(nome_portal), 'wb') as f:\n",
    "        pickle.dump(df,f)\n",
    "        f.close()\n",
    "    \n",
    "# Junta a informação de manchetes já existentes com as novas coletadas, adicionando apenas manchetes novas\n",
    "def adicionar_infos_novas(df_antigo,infos_novas): \n",
    "    df_final= df_antigo.append(infos_novas).drop_duplicates(subset='manchete',ignore_index=True) \n",
    "    \n",
    "    return df_final\n",
    "    \n",
    "    \n",
    "\n",
    "def coletando_infos(nome_portal):\n",
    "    if nome_portal == 'Band':\n",
    "        lista_manchetes = coletando_infos_band()\n",
    "    elif nome_portal == 'BBC':\n",
    "        lista_manchetes = coletando_infos_bbc()\n",
    "    elif nome_portal == 'Folha de SP':\n",
    "        lista_manchetes = coletando_infos_folha()\n",
    "    elif nome_portal == 'Gazeta do Povo':\n",
    "        lista_manchetes = coletando_infos_gazeta()\n",
    "    elif nome_portal == 'Globo':\n",
    "        lista_manchetes = coletando_infos_globo()\n",
    "    elif nome_portal == 'iG':\n",
    "        lista_manchetes = coletando_infos_ig()\n",
    "    elif nome_portal == 'R7':\n",
    "        lista_manchetes = coletando_infos_r7()\n",
    "    elif nome_portal == 'UOL':\n",
    "        lista_manchetes = coletando_infos_uol()\n",
    "    elif nome_portal == 'Veja':\n",
    "        lista_manchetes = coletando_infos_veja()\n",
    "    elif nome_portal == 'Carta Capital':\n",
    "        lista_manchetes = coletando_infos_carta_capital()\n",
    "    elif nome_portal == 'Revista Forúm':\n",
    "        lista_manchetes = coletando_infos_forum()\n",
    "    elif nome_portal == 'Brasil de Fato':\n",
    "        lista_manchetes = coletando_infos_brasil_fato()\n",
    "    elif nome_portal == 'Pleno News':\n",
    "        lista_manchetes = coletando_infos_pleno()\n",
    "    elif nome_portal == 'Terça Livre':\n",
    "        lista_manchetes = coletando_infos_terca_livre()\n",
    "    elif nome_portal == 'Renova Mídia':\n",
    "        lista_manchetes = coletando_infos_renova()\n",
    "    elif nome_portal == 'Conexão Política':\n",
    "        lista_manchetes = coletando_infos_conexao()\n",
    "    elif nome_portal == 'Jornal da Cidade':\n",
    "        lista_manchetes = coletando_infos_jornal_cidade()\n",
    "    elif nome_portal == 'El Pais':\n",
    "        lista_manchetes = coletando_infos_elpais()\n",
    "    elif nome_portal == 'Deutsche Welle':\n",
    "        lista_manchetes = coletando_infos_dw()\n",
    "    elif nome_portal == 'Estadão':\n",
    "        lista_manchetes = coletando_infos_estadao()\n",
    "    elif nome_portal == 'Isto É':\n",
    "        lista_manchetes = coletando_infos_istoe()\n",
    "    \n",
    "    df = pd.DataFrame(lista_manchetes, columns=['data','portal','manchete'])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coletando_todas_infos(todos_portais):\n",
    "    for portal in todos_portais:\n",
    "        df_antigo = abrir_pickle(portal)\n",
    "        tamanho_anterior = df_antigo.shape[0]\n",
    "        \n",
    "        novo_df = coletando_infos(portal)\n",
    "        \n",
    "        df_final = adicionar_infos_novas(df_antigo,novo_df)\n",
    "        tamanho_novo = df_final.shape[0]\n",
    "        \n",
    "        salvar_pickle(df_final,portal)\n",
    "        \n",
    "        print('{} --- Antes: {} - Depois: {} --- Diferença: {}'.format(portal,tamanho_anterior,tamanho_novo,tamanho_novo-tamanho_anterior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checando_infos(todos_portais):\n",
    "    for portal in todos_portais:\n",
    "        if portal=='Globo':\n",
    "            df = abrir_pickle(portal)\n",
    "            print(df.tail(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band --- Antes: 3103 - Depois: 3139 --- Diferença: 36\n",
      "BBC --- Antes: 1133 - Depois: 1151 --- Diferença: 18\n",
      "Folha de SP --- Antes: 7257 - Depois: 7316 --- Diferença: 59\n",
      "Gazeta do Povo --- Antes: 4802 - Depois: 4865 --- Diferença: 63\n",
      "Globo --- Antes: 11793 - Depois: 11849 --- Diferença: 56\n",
      "iG --- Antes: 9130 - Depois: 9222 --- Diferença: 92\n",
      "R7 --- Antes: 10724 - Depois: 10819 --- Diferença: 95\n",
      "UOL --- Antes: 13076 - Depois: 13076 --- Diferença: 0\n",
      "Veja --- Antes: 5836 - Depois: 5906 --- Diferença: 70\n",
      "Carta Capital --- Antes: 2271 - Depois: 2298 --- Diferença: 27\n",
      "Revista Forúm --- Antes: 2727 - Depois: 2768 --- Diferença: 41\n",
      "Brasil de Fato --- Antes: 1729 - Depois: 1755 --- Diferença: 26\n",
      "Pleno News --- Antes: 3231 - Depois: 3273 --- Diferença: 42\n",
      "Terça Livre --- Antes: 703 - Depois: 708 --- Diferença: 5\n",
      "Renova Mídia --- Antes: 1340 - Depois: 1354 --- Diferença: 14\n",
      "Conexão Política --- Antes: 225 - Depois: 225 --- Diferença: 0\n",
      "Jornal da Cidade --- Antes: 1504 - Depois: 1535 --- Diferença: 31\n",
      "El Pais --- Antes: 1769 - Depois: 1790 --- Diferença: 21\n",
      "Deutsche Welle --- Antes: 1670 - Depois: 1689 --- Diferença: 19\n",
      "Estadão --- Antes: 3623 - Depois: 3651 --- Diferença: 28\n",
      "Isto É --- Antes: 7331 - Depois: 7380 --- Diferença: 49\n"
     ]
    }
   ],
   "source": [
    "coletando_todas_infos(todos_portais)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      data portal  \\\n",
      "11799  04/10/2021 19:43:52  Globo   \n",
      "11800  04/10/2021 19:43:52  Globo   \n",
      "11801  04/10/2021 19:43:52  Globo   \n",
      "11802  04/10/2021 19:43:52  Globo   \n",
      "11803  04/10/2021 19:43:52  Globo   \n",
      "11804  04/10/2021 19:43:52  Globo   \n",
      "11805  04/10/2021 19:43:52  Globo   \n",
      "11806  04/10/2021 19:43:52  Globo   \n",
      "11807  04/10/2021 19:43:52  Globo   \n",
      "11808  04/10/2021 19:43:52  Globo   \n",
      "11809  04/10/2021 19:43:52  Globo   \n",
      "11810  04/10/2021 19:43:52  Globo   \n",
      "11811  04/10/2021 19:43:52  Globo   \n",
      "11812  04/10/2021 19:43:52  Globo   \n",
      "11813  04/10/2021 19:43:52  Globo   \n",
      "11814  04/10/2021 19:43:52  Globo   \n",
      "11815  04/10/2021 19:43:52  Globo   \n",
      "11816  04/10/2021 19:43:52  Globo   \n",
      "11817  04/10/2021 19:43:52  Globo   \n",
      "11818  04/10/2021 19:43:52  Globo   \n",
      "11819  04/10/2021 19:43:52  Globo   \n",
      "11820  04/10/2021 19:43:52  Globo   \n",
      "11821  04/10/2021 19:43:52  Globo   \n",
      "11822  04/10/2021 19:43:52  Globo   \n",
      "11823  04/10/2021 19:43:52  Globo   \n",
      "11824  04/10/2021 19:43:52  Globo   \n",
      "11825  04/10/2021 19:43:52  Globo   \n",
      "11826  04/10/2021 19:43:52  Globo   \n",
      "11827  04/10/2021 19:43:52  Globo   \n",
      "11828  04/10/2021 19:43:52  Globo   \n",
      "11829  04/10/2021 19:43:52  Globo   \n",
      "11830  04/10/2021 19:43:52  Globo   \n",
      "11831  04/10/2021 19:43:52  Globo   \n",
      "11832  04/10/2021 19:43:52  Globo   \n",
      "11833  04/10/2021 19:43:52  Globo   \n",
      "11834  04/10/2021 19:43:52  Globo   \n",
      "11835  04/10/2021 19:43:52  Globo   \n",
      "11836  04/10/2021 19:43:52  Globo   \n",
      "11837  04/10/2021 19:43:52  Globo   \n",
      "11838  04/10/2021 19:43:52  Globo   \n",
      "11839  04/10/2021 19:43:52  Globo   \n",
      "11840  04/10/2021 19:43:52  Globo   \n",
      "11841  04/10/2021 19:43:52  Globo   \n",
      "11842  04/10/2021 19:43:52  Globo   \n",
      "11843  04/10/2021 19:43:52  Globo   \n",
      "11844  04/10/2021 19:43:52  Globo   \n",
      "11845  04/10/2021 19:43:52  Globo   \n",
      "11846  04/10/2021 19:43:52  Globo   \n",
      "11847  04/10/2021 19:43:52  Globo   \n",
      "11848  04/10/2021 19:43:52  Globo   \n",
      "\n",
      "                                                manchete  \n",
      "11799  Abel Ferreira tem razão? Compare a defesa do P...  \n",
      "11800  Trio da Premier League fica no 'pódio', e Barç...  \n",
      "11801  Pilar descobrirá quem é o verdadeiro amante da...  \n",
      "11802  Grávida, Thaila Ayala passeia em shopping e mo...  \n",
      "11803      Veja atores de 'O Clone' 20 anos após estreia  \n",
      "11804  Protagonistas, Antonelli e Benício são elogiad...  \n",
      "11805     Funcionários tentam resolver falha manualmente  \n",
      "11806    Sem WhatsApp, dobra uso de ligações telefônicas  \n",
      "11807  Mark Zuckerberg perde US$ 7 bilhões em poucas ...  \n",
      "11808  Zuckerberg perde o posto de 4º mais rico para ...  \n",
      "11809  'Esqueci que podia ligar', diz usuária sem soc...  \n",
      "11810       Trabalhadores em home office recorrem ao SMS  \n",
      "11811  'Sou vítima, diz deputado acusado de forjar at...  \n",
      "11812      PGR denuncia deputado bolsonarista ao Supremo  \n",
      "11813      CPI quer criar memorial para vítimas da Covid  \n",
      "11814         Oposição vai ao MPF por offshore de Guedes  \n",
      "11815  Barroso sobre voto impresso: 'Defunto foi ente...  \n",
      "11816  Urnas: TSE faz cerimônia de abertura do código...  \n",
      "11817  Veja 7 situações para evitar riscos ao usar ce...  \n",
      "11818  Sabe tudo sobre o Mundial de LoL? Quiz testa s...  \n",
      "11819  Far Cry 6, Metroid Dread e Alan Wake são desta...  \n",
      "11820  Proibido: 5 coisas que você não deve fazer no ...  \n",
      "11821  Cresce o número de pets adotados no Brasil dur...  \n",
      "11822  Dicas para escolher tapetes ideais para os ani...  \n",
      "11823  Conheça alguns pets famosos de celebridades ap...  \n",
      "11824  Aos 76 anos, Helen Mirren cruza passarela da P...  \n",
      "11825  9 tendências que vão ditar os rumos de beleza ...  \n",
      "11826  A minissaia é uma das principais sugestões nos...  \n",
      "11827  Marieta Severo diz como lida com os efeitos do...  \n",
      "11828  Lembra-se de como era o mundo em 2012, ano em ...  \n",
      "11829  Em clima de nostalgia, internet relembra rede ...  \n",
      "11830  1ª atriz a fazer nu frontal no teatro conta qu...  \n",
      "11831  'Os Roni' está com nova temporada no Multishow...  \n",
      "11832  Nove temporadas de 'Chegado Fire' para os fãs ...  \n",
      "11833  Doc 'Fênix' mostra como um bombeiro transformo...  \n",
      "11834  Pane é global: WhatsApp, Instagram e Facebook ...  \n",
      "11835  WhatsApp fora do ar: o que se sabe e o que não...  \n",
      "11836  5xx Server Error: entenda o erro que tirou Wha...  \n",
      "11837  Repórter do 'Mais Você' cai em golpe por celul...  \n",
      "11838  Pai de mulher morta por 5 foi socorrer vítima ...  \n",
      "11839  Mbappé revela que chegou a pedir para deixar o...  \n",
      "11840  Grêmio fracassa em nova chance para deixar Z-4...  \n",
      "11841  Veja as chances matemáticas de Fla e Palmeiras...  \n",
      "11842  FIFA 22: veja comparativo gráfico entre PS5 e PS4  \n",
      "11843  São Paulo debate situação de Crespo e mantém o...  \n",
      "11844  Romário surge com novo affair em Florianópolis...  \n",
      "11845  Bruna Marquezine ousa com sutiã transparente p...  \n",
      "11846  'O Clone': Veja como estão os atores 20 anos d...  \n",
      "11847  Grávida de Hulk, Camila Ângelo exibe a barrigu...  \n",
      "11848  Desvendemos os melhores looks de Bruna Marquez...  \n"
     ]
    }
   ],
   "source": [
    "checando_infos(todos_portais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
